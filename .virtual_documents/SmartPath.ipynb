








# Importing libraries
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt





# Defining path to the dataset folder
data_path = './datasets'

# Loading core datasets 
occupation_df = pd.read_csv(os.path.join(data_path, 'Occupation Data.txt'), delimiter='\t')
interests_df = pd.read_csv(os.path.join(data_path, 'Interests.txt'), delimiter='\t')
skills_df = pd.read_csv(os.path.join(data_path, 'Skills.txt'), delimiter='\t')
education_df = pd.read_csv(os.path.join(data_path, 'Education, Training, and Experience.txt'), delimiter='\t')
related_df = pd.read_csv(os.path.join(data_path, 'Related Occupations.txt'), delimiter='\t')
abilities_df = pd.read_csv('datasets/Abilities.txt', sep='\t', encoding='utf-8')
emerging_tasks_df = pd.read_csv('datasets/Emerging Tasks.txt', sep='\t', encoding='utf-8')
edu_categories_df = pd.read_csv('datasets/Education, Training, and Experience Categories.txt', sep='\t', encoding='utf-8')





# View structure of each DataFrame
print("Occupations:", occupation_df.shape)
print("Interests:", interests_df.shape)
print("Skills:", skills_df.shape)
print("Education:", education_df.shape)
print("Related Jobs:", related_df.shape)
print("Abilities:", abilities_df.shape)
print("Emerging Tasks:", emerging_tasks_df.shape)
print("Education Categories:", edu_categories_df.shape)

# Display sample rows
occupation_df.head(3)


occupation_df.head()
interests_df.head()
skills_df.head()
education_df.head()
related_df.head()
abilities_df.head()





# See column names
occupation_df.columns  
interests_df.columns
skills_df.columns
education_df.columns
related_df.columns








# Renaming for clarity
# Standardize 'O*NET-SOC Code' column name
for df in [occupation_df, interests_df, skills_df, education_df, related_df, emerging_tasks_df, edu_categories_df]:
    df.rename(columns={'O*NET-SOC Code': 'ONET_Code'}, inplace=True)

# Standardize abilities columns
abilities_df = abilities_df[['O*NET-SOC Code', 'Element Name', 'Scale ID', 'Data Value']]
abilities_df.rename(columns={'O*NET-SOC Code': 'ONET_Code', 'Element Name': 'Ability'}, inplace=True)
abilities_df = abilities_df[abilities_df['Scale ID'] == 'IM']  # Only Importance scale
abilities_df.drop(columns='Scale ID', inplace=True)














# Pivoting the interests to get one row per job with RIASEC scores
riasec_df = interests_df.pivot_table(index='ONET_Code',
                                     columns='Element Name',
                                     values='Data Value').reset_index()

# Renaming columns for consistency
riasec_df.columns.name = None  # To remove multiindex
riasec_df.rename(columns={
    'Realistic': 'R',
    'Investigative': 'I',
    'Artistic': 'A',
    'Social': 'S',
    'Enterprising': 'E',
    'Conventional': 'C'
}, inplace=True)

# Preview RIASEC vectors
riasec_df.head()








# Exploring what's in skills_df
skills_df['Scale ID'].value_counts()








# Filtering only 'Importance' scores
important_skills_df = skills_df[skills_df['Scale ID'] == 'IM']

# Keeping top 10 most important skills per job
top_skills_df = important_skills_df.groupby('ONET_Code', group_keys=False).apply(
    lambda x: x.sort_values(by='Data Value', ascending=False).head(10)
).reset_index(drop=True)

# Preview of top skills for one job
top_skills_df[top_skills_df['ONET_Code'] == '11-1011.00']








# Top 10 Skills for a Sample Job
onet_id = '11-1011.00'  
job_skills = top_skills_df[top_skills_df['ONET_Code'] == onet_id]

plt.figure(figsize=(14,6))
sns.barplot(x='Data Value', y='Element Name', data=job_skills.sort_values('Data Value'))
plt.title("Top 10 Important Skills: Chief Executives")
plt.xlabel("Importance Score")
plt.ylabel("Skill")
plt.tight_layout()
plt.show()











# Merging education data with categories
education_df_with_cat = education_df.merge(
    edu_categories_df[['Element ID', 'Category', 'Category Description']],
    on='Element ID',
    how='left'
)





print(education_df_with_cat.columns.tolist())



# Renaming columns for clarity with actual column names in the DataFrame
education_df_with_cat.rename(columns={
    'Category_y': 'Preparation Type',           # <-- correct source from merged df
    'Category Description': 'Preparation Level',
    'Element Name': 'Prep Component'
}, inplace=True)


# Preview DataFrame
education_df_with_cat[['ONET_Code', 'Prep Component', 'Preparation Type', 'Preparation Level']].head()





# Getting the most common (highest scoring) education level per job, now with category
edu_df_with_cat = (
    education_df_with_cat
    .sort_values(by='Data Value', ascending=False)
    .drop_duplicates(subset='ONET_Code')
    [['ONET_Code', 'Prep Component', 'Data Value', 'Preparation Type', 'Preparation Level']]
    .rename(columns={
        'Prep Component': 'Education Level',
        'Preparation Type': 'Education Category'
    })
)

# Preview the result
edu_df_with_cat.head()








# Creating full job profile
job_profiles = occupation_df.merge(riasec_df, on='ONET_Code', how='left')
job_profiles = job_profiles.merge(edu_df_with_cat, on='ONET_Code', how='left')

# Preview 
job_profiles[['Title', 'Description', 'Education Level', 'Education Category', 'Preparation Level']].head()








# Checking for duplicates
job_profiles.duplicated().sum()





# Checking missing values across all columns
job_profiles.isnull().sum()





# Dropping rows with missing education info
job_profiles_clean = job_profiles.dropna(subset=['Education Level', 'Education Category', 'Preparation Level'])





#  Filling missing RIASEC Interests with "Unknown"
job_profiles_clean.loc[:, interest_cols] = job_profiles_clean[interest_cols].fillna('Unknown')


job_profiles_clean





from sklearn.preprocessing import MinMaxScaler

riasec_cols = ['R', 'I', 'A', 'S', 'E', 'C']
scaler = MinMaxScaler()
job_profiles[riasec_cols] = scaler.fit_transform(job_profiles[riasec_cols])
job_profiles[riasec_cols] 








# Dropping rows with missing RIASEC values
job_profiles_no_nulls = job_profiles.dropna(subset=riasec_cols).copy()

# Normalize RIASEC columns 
scaler = MinMaxScaler()
job_profiles_no_nulls.loc[:, riasec_cols] = scaler.fit_transform(job_profiles_no_nulls[riasec_cols])

# Updating original job_profiles DataFrame with normalized values
job_profiles.update(job_profiles_no_nulls)





### Normalize Education Score for filtering or weighted scoring.
scaler = MinMaxScaler()
job_profiles_clean.loc[:, 'Normalized Education Score'] = scaler.fit_transform(
    job_profiles_clean[['Data Value']]
)





# Checking unique values in Education Category and Preparation Level
print("Unique Education Category values:")
print(job_profiles_clean['Education Category'].sort_values().unique())

print("\nUnique Preparation Level values:")
print(job_profiles_clean['Preparation Level'].sort_values().unique())





# Creating an Education Level Dictionary
education_level_map = {
    1.0: "Less than High School",
    2.0: "High School Diploma or equivalent",
    3.0: "Post-Secondary Certificate",
    4.0: "Some College Courses",
    5.0: "Associate's Degree",
    6.0: "Bachelor's Degree",
    7.0: "Post-Baccalaureate Certificate",
    8.0: "Master's Degree",
    9.0: "Post-Master's Certificate",
    10.0: "First Professional Degree",
    11.0: "Doctoral Degree",
    12.0: "Post-Doctoral Training"
}

# Adding a readable education label
job_profiles_clean.loc[:, 'Education Category Label'] = job_profiles_clean['Education Category'].map(education_level_map)
job_profiles_clean[['Education Category', 'Education Category Label', 'Preparation Level']].head(10)





# Check for any Education values with missing category labels
job_profiles_clean[job_profiles_clean['Education Category Label'].isnull()]





# Defining RIASEC columns
riasec_cols = ['R', 'I', 'A', 'S', 'E', 'C']

# Setting plot style
sns.set(style="whitegrid")
plt.figure(figsize=(14, 6))

# Melting the DataFrame for seaborn
riasec_melted = job_profiles_clean.melt(
    value_vars=riasec_cols, 
    var_name='RIASEC Type', 
    value_name='Score'
)

# Plot distribution
sns.boxplot(
    x='RIASEC Type', 
    y='Score', 
    hue='RIASEC Type',
    data=riasec_melted, 
    palette='Set2', 
    legend=False
)

plt.title('Distribution of RIASEC Scores Across All Jobs', fontsize=14)
plt.ylabel('Score (0–7)')
plt.xlabel('RIASEC Type')
plt.grid(True)
plt.tight_layout()
plt.show()











from sklearn.metrics.pairwise import cosine_similarity
import numpy as np





# RIASEC scores: [Realistic, Investigative, Artistic, Social, Enterprising, Conventional]
# Sample user RIASEC profile (scale: 0–7)
user_profile = {
    'R': 2.0,
    'I': 6.0,
    'A': 4.0,
    'S': 5.0,
    'E': 3.0,
    'C': 1.0
}





# Extracting job RIASEC features
job_riasec_vectors = job_profiles_clean[riasec_cols].values

# Converting user profile to vector
user_vector = np.array(list(user_profile.values())).reshape(1, -1)





# Computing similarity between user and all job profiles
similarities = cosine_similarity(user_vector, job_riasec_vectors)[0]

# Flatten similarity array
job_profiles_clean.loc[:, 'Similarity Score'] = similarities
job_profiles_clean





# Similarity Score Distribution 
sns.histplot(job_profiles['Similarity'], bins=20, color='orange')
plt.title("Similarity Scores Between User and Jobs")
plt.xlabel("Cosine Similarity")
plt.ylabel("Number of Jobs")
plt.show()








# Sorting and viewing top 10 matches
top_matches = job_profiles.sort_values(by='Similarity', ascending=False).head(10)

# Show selected columns
top_matches[['Title', 'Description', 'Similarity']]








# Defining example user input
user_riasec = {
    'R': 3.0,
    'I': 4.5,
    'A': 2.0,
    'S': 5.0,
    'E': 3.5,
    'C': 1.0
}

# Converting to NumPy array for comparison
user_vector = np.array([list(user_riasec.values())])





import plotly.graph_objects as go

# Get RIASEC of user and top match
categories = ['R', 'I', 'A', 'S', 'E', 'C']
user_scores = user_vector.flatten()
top_job_scores = top_matches.iloc[0][categories].values  # First match

# Radar plot
fig = go.Figure()
fig.add_trace(go.Scatterpolar(r=user_scores, theta=categories, fill='toself', name='User'))
fig.add_trace(go.Scatterpolar(r=top_job_scores, theta=categories, fill='toself', name='Top Job Match'))

fig.update_layout(polar=dict(radialaxis=dict(visible=True)), title="RIASEC Match: User vs Top Job")
fig.show()











# Mapping education to numeric levels
education_levels = {
    'No formal educational credential': 0,
    'High school diploma or equivalent': 1,
    'Some college, no degree': 2,
    'Associate\'s degree': 3,
    'Bachelor\'s degree': 4,
    'Master\'s degree': 5,
    'Doctoral or professional degree': 6
}





# Creating a mapping manually 
edu_mapping = {
    'No formal educational credential': 0,
    'High school diploma or equivalent': 1,
    'Some college, no degree': 2,
    'Associate\'s degree': 3,
    'Bachelor\'s degree': 4,
    'Master\'s degree': 5,
    'Doctoral or professional degree': 6,
    'Related Work Experience': 3,     
    'Postsecondary non-degree award': 2,
    'Required Level of Education': 4, 
    'Less than high school diploma': 0
}

# Applying to job_profiles
job_profiles['Education_Level_Code'] = job_profiles['Education Level'].map(edu_mapping)





user_education_level = 5 

# Removing jobs requiring more education than the user has
filtered_jobs = job_profiles[job_profiles['Education_Level_Code'] <= user_education_level]

# Sorting by similarity and show top 10
top_filtered_matches = filtered_jobs.sort_values(by='Similarity', ascending=False).head(10)

# Results
top_filtered_matches[['Title', 'Description', 'Similarity', 'Education Level']]








# Preparing data
option_a_scores = top_matches['Similarity'].values
option_b_scores = top_filtered_matches['Similarity'].values
titles = [f'{i+1}' for i in range(len(option_a_scores))]

# Plot
plt.figure(figsize=(10, 5))
plt.plot(titles, option_a_scores, marker='o', label='Option A (RIASEC Only)')
plt.plot(titles, option_b_scores, marker='o', label='Option B (RIASEC + Education)')
plt.title('Top 10 Job Matches: Similarity Score Comparison')
plt.xlabel('Rank')
plt.ylabel('Cosine Similarity')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
plt.show()








# Counting jobs before and after filtering
total_jobs = len(job_profiles)
filtered_jobs_count = len(filtered_jobs)

# Bar plot
plt.bar(['Before Filter', 'After Filter'], [total_jobs, filtered_jobs_count], color=['#3498db', '#2ecc71'])
plt.title('Jobs Remaining After Education Filter')
plt.ylabel('Number of Jobs')
plt.show()








# Merging top 10 job matches (Option A or B) with top skills
def attach_skills(top_jobs, skills_df):
    skill_info = skills_df[['ONET_Code', 'Element Name', 'Data Value']]
    merged = top_jobs.merge(skill_info, on='ONET_Code', how='left')
    return merged

# Example with Option B
top_b_with_skills = attach_skills(top_filtered_matches, top_skills_df)

# Preview(Show job, skill, and importance score)
top_b_with_skills[['Title', 'Element Name', 'Data Value_y']].head(15)





# Renaming Data Value_y  to "Skill Importance" for clarity 
top_b_with_skills.rename(columns={'Data Value_y': 'Skill Importance'}, inplace=True)
top_b_with_skills[['Title', 'Element Name', 'Skill Importance']].head(15)





# Attaching top skills to top jobs
def attach_skills(top_jobs, skills_df):
    skill_info = skills_df[['ONET_Code', 'Element Name', 'Data Value']]
    merged = top_jobs.merge(skill_info, on='ONET_Code', how='left')
    merged.rename(columns={'Element Name': 'Skill'}, inplace=True)
    return merged

# Attaching top abilities
def attach_abilities(top_jobs, abilities_df):
    ability_info = abilities_df[['ONET_Code', 'Ability', 'Data Value']].copy()
    merged = top_jobs.merge(ability_info, on='ONET_Code', how='left')
    return merged

# Attaching emerging tasks
def attach_emerging_tasks(top_jobs, tasks_df):
    task_info = tasks_df[['ONET_Code', 'Task']].drop_duplicates()
    merged = top_jobs.merge(task_info, on='ONET_Code', how='left')
    return merged

# Attaching Education, Training & Experience Categories
def attach_edu_categories(top_jobs, edu_cat_df):
    cat_info = edu_cat_df[['ONET_Code', 'Category']].drop_duplicates()
    merged = top_jobs.merge(cat_info, on='ONET_Code', how='left')
    return merged


# Attaching Skills
top_b_with_skills = attach_skills(top_filtered_matches, top_skills_df)

# Attaching Abilities
top_b_with_abilities = attach_abilities(top_b_with_skills, abilities_df)

# Attaching Emerging Tasks
top_b_with_tasks = attach_emerging_tasks(top_b_with_abilities, emerging_tasks_df)

# Merging education info into top_b_with_tasks to create top_b_enhanced
top_b_enhanced = top_b_with_tasks.merge(
    edu_df_with_cat[['ONET_Code', 'Education Level', 'Education Category']],
    on='ONET_Code',
    how='left'
)

top_b_enhanced.rename(columns={
    'Data Value_y': 'Skill Score',
    'Education Level_y': 'Top Education Level',
    'Education Category_y': 'Education Category'
}, inplace=True)

# Result
top_b_enhanced[['Title', 'Skill', 'Skill Score', 'Ability', 'Task', 'Top Education Level', 'Education Category']].head(10)


missing_tasks = top_b_enhanced['Task'].isna().sum()
print(f"{missing_tasks} of {len(top_b_enhanced)} top job matches have no emerging tasks listed.")





top_b_enhanced['Task'] = top_b_enhanced['Task'].fillna('No Emerging Task Listed')
top_b_enhanced[['Title', 'Skill', 'Skill Score', 'Ability', 'Task', 'Top Education Level', 'Education Category']].head(10)








top_skills_plot = (
    top_b_enhanced['Skill']
    .value_counts()
    .nlargest(10)
    .sort_values()
)

plt.figure(figsize=(10, 6))
sns.barplot(
    x=top_skills_plot.values,
    y=top_skills_plot.index,
    hue=top_skills_plot.index,  # Set hue to match the y-axis variable
    dodge=False,
    palette='viridis',
    legend=False  # Optional: Hides legend since it's redundant
)
plt.title('Top 10 Most Common Skills Across Top Jobs')
plt.xlabel('Count')
plt.ylabel('Skill')
plt.tight_layout()
plt.show()





top_abilities_plot = (
    top_b_enhanced['Ability']
    .value_counts()
    .nlargest(10)
    .sort_values()
)

plt.figure(figsize=(10, 6))
sns.barplot(
    x=top_abilities_plot.values,
    y=top_abilities_plot.index,
    hue=top_abilities_plot.index,
    palette='coolwarm',
    legend=False
)
plt.title('Top 10 Most Common Abilities Across Top Jobs')
plt.xlabel('Count')
plt.ylabel('Ability')
plt.tight_layout()
plt.show()





top_edu_plot = (
    top_b_enhanced['Top Education Level']
    .value_counts()
    .sort_values()
)

plt.figure(figsize=(10, 6))
sns.barplot(
    x=top_edu_plot.values,
    y=top_edu_plot.index,
    hue=top_edu_plot.index,
    palette='Set2',
    legend=False
)
plt.title('Most Common Education Levels in Top Jobs')
plt.xlabel('Count')
plt.ylabel('Education Level')
plt.tight_layout()
plt.show()














# Radar chart for top 5 abilities of the top job match
top_job_title = top_b_enhanced.iloc[0]['Title']
top_abilities = top_b_enhanced[top_b_enhanced['Title'] == top_job_title].nlargest(5, 'Data Value')

categories = top_abilities['Ability']
values = top_abilities['Data Value']

fig = go.Figure()
fig.add_trace(go.Scatterpolar(
    r=values,
    theta=categories,
    fill='toself',
    name='Top Job Abilities'
))
fig.update_layout(
    polar=dict(radialaxis=dict(visible=True, range=[0, 5])),
    title=f"Top 5 Abilities for '{top_job_title}'"
)
fig.show()



